{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing pandas package with alias pd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a data frame - dictionary is used here where keys get converted to column names and values to row values.\n",
    "data = pd.DataFrame({'Country': ['Russia','Colombia','Chile','Equador','Nigeria'],\n",
    "                    'Rank':[121,40,100,130,11]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe() method computes summary statistics of integer / double variables\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info() gives a more detailed statistics about data in dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'group':['a', 'a', 'a', 'b','b', 'b', 'c', 'c','c'],'ounces':[4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "# head(n) gives first n rows of dataframe\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's sort the data frame by ounces - inplace = True will make changes to the data\n",
    "data.sort_values(by=['ounces'],ascending=True,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting on multiple columns\n",
    "data.sort_values(by=['group','ounces'],ascending=[True,False],inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we get data sets with duplicate rows, which is nothing but noise. Therefore, before training the model, we need to make sure we get rid of such inconsistencies in the data set. Let's see how we can remove duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'k1':['one']*3 + ['two']*4, 'k2':[3,2,1,3,3,4,4]})\n",
    "data.sort_values(by='k2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates \n",
    "data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we removed duplicates based on matching row values across all columns. Alternatively, we can also remove duplicates based on a particular column. Let's remove duplicate values from the k1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset='k1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how we can add a new column to our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = pd.DataFrame({'food': ['bacon', 'pulled pork', 'bacon', 'Pastrami','corned beef', 'Bacon', 'pastrami', 'honey ham','nova lox'],\n",
    "                 'ounces': [4, 3, 12, 6, 7.5, 8, 3, 5, 6]})\n",
    "# Creates a new column protien and assigns 9 random values to it\n",
    "data = data.assign(protien = np.random.random(9))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove the added columns\n",
    "data.drop('protien',axis='columns',inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how we can use slice on DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range('20130101',periods=6)\n",
    "df = pd.DataFrame(np.random.randn(6,4),index=dates,columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first n rows from the data frame\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slice based on date range\n",
    "df['20130101':'20130104']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing based on column names\n",
    "df.loc[:,['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['20130102':'20130103',['A','B']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#slicing based on index of columns\n",
    "df.iloc[3] #returns 4th row (index is 3rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns a specific range of rows\n",
    "df.iloc[2:4, 0:2] # Selects rows from 2:4 and columns from 0:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comapring\n",
    "df['B'] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing based on column values as well. This helps in filtering a data set based on a pre-defined condition\n",
    "df[df['B'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use a query method to select columns based on a criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list all columns where A is greater than C\n",
    "df.query('A > C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using OR condition\n",
    "df.query('A < B | C > A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file using pandas into a DataFrame\n",
    "iris = pd.read_csv('Iris.csv')\n",
    "iris.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot things is using the .plot extension from Pandas dataframes\n",
    "# We'll use this to make a scatterplot of the Iris features.\n",
    "%matplotlib inline\n",
    "iris.plot(kind=\"scatter\", x=\"SepalLengthCm\", y=\"SepalWidthCm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing some visualization libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "sns.set(style=\"white\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One piece of information missing in the plots above is what species each plant is\n",
    "# We'll use seaborn's FacetGrid to color the scatterplot by species\n",
    "sns.FacetGrid(iris, hue=\"Species\", size=5) \\\n",
    "   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n",
    "   .add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at an individual feature in Seaborn through a boxplot\n",
    "sns.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another useful seaborn plot is the pairplot, which shows the bivariate relation\n",
    "# between each pair of features\n",
    "# \n",
    "# From the pairplot, we'll see that the Iris-setosa species is separataed from the other\n",
    "# two across all feature combinations\n",
    "sns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots can also be made using DataFrame\n",
    "iris.drop(\"Id\", axis=1).boxplot(by=\"Species\",figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Algorithms and Decision Boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our Species column which contains these three class labels contain categorical data, the first thing to do would be to encode them numerically as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'Iris-setosa':0, 'Iris-versicolor':1,'Iris-virginica':2 }\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "iris['Species'] = iris['Species'].apply(lambda x: target_map[x])\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing alll the necessary packages to use the various classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n",
    "from sklearn.cross_validation import train_test_split #to split the dataset for training and testing\n",
    "from sklearn import metrics #for checking the model accuracy\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "from sklearn.ensemble import RandomForestClassifier # A combine model of many decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation among features\n",
    "When we train any algorithm, the number of features and their correlation plays an important role. If there are features and many of the features are highly correlated, then training an algorithm with all the featues will reduce the accuracy. Thus features selection should be done carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "Y = iris['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8)) \n",
    "sns.heatmap(X.corr(),annot=True,cmap='cubehelix_r') #draws  heatmap with input as the correlation matrix calculted by(iris.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation\n",
    "The Sepal Width and Length are not correlated The Petal Width and Length are highly correlated\n",
    "\n",
    "We will use all the features for training the algorithm and check the accuracy.\n",
    "\n",
    "Then we will use 1 Petal Feature and 1 Sepal Feature to check the accuracy of the algorithm as we are using only 2 features that are not correlated. Thus we can have a variance in the dataset which may help in better accuracy. We will check it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Steps To Be followed When Applying an Algorithm\n",
    "\n",
    "-    Split the dataset into training and testing dataset. The testing dataset is generally smaller than training one as it will help in training the model better.\n",
    "\n",
    "-    Select any algorithm based on the problem (classification or regression) whatever you feel may be good.\n",
    "\n",
    "-    Then pass the training dataset to the algorithm to train it.\n",
    "\n",
    "-    Then pass the testing data to the trained algorithm to predict the outcome.\n",
    "\n",
    "-    We then check the accuracy by passing the predicted outcome and the actual output to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting The Data into Training And Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(iris, test_size = 0.3, random_state=1212)# in this our main data is split into train and test\n",
    "# the attribute test_size=0.3 splits the data into 70% and 30% ratio. train=70% and test=30%\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = train[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]# taking the training data features\n",
    "train_y = train.Species# output of our training data\n",
    "test_X = test[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']] # taking test data features\n",
    "test_y = test.Species   #output value of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_X,train_y)\n",
    "prediction = model.predict(test_X)\n",
    "print('The accuracy of the Logistic Regression is',metrics.accuracy_score(prediction,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "model.fit(train_X,train_y)\n",
    "prediction = model.predict(test_X)\n",
    "print('The accuracy of the Decision Tree is',metrics.accuracy_score(prediction,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used all the features of iris in above models. Now we will use Petals and Sepals Seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "petal=iris[['PetalLengthCm','PetalWidthCm','Species']]\n",
    "sepal=iris[['SepalLengthCm','SepalWidthCm','Species']]\n",
    "\n",
    "train_p,test_p=train_test_split(petal,test_size=0.3,random_state=0)  #petals\n",
    "train_x_p=train_p[['PetalWidthCm','PetalLengthCm']]\n",
    "train_y_p=train_p.Species\n",
    "test_x_p=test_p[['PetalWidthCm','PetalLengthCm']]\n",
    "test_y_p=test_p.Species\n",
    "\n",
    "\n",
    "train_s,test_s=train_test_split(sepal,test_size=0.3,random_state=0)  #Sepal\n",
    "train_x_s=train_s[['SepalWidthCm','SepalLengthCm']]\n",
    "train_y_s=train_s.Species\n",
    "test_x_s=test_s[['SepalWidthCm','SepalLengthCm']]\n",
    "test_y_s=test_s.Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(train_x_p,train_y_p) \n",
    "prediction=model.predict(test_x_p) \n",
    "print('The accuracy of the Logistic Regression using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n",
    "\n",
    "model.fit(train_x_s,train_y_s) \n",
    "prediction=model.predict(test_x_s) \n",
    "print('The accuracy of the Logistic Regression using Sepals is:',metrics.accuracy_score(prediction,test_y_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=DecisionTreeClassifier()\n",
    "model.fit(train_x_p,train_y_p) \n",
    "prediction=model.predict(test_x_p) \n",
    "print('The accuracy of the Decision Tree using Petals is:',metrics.accuracy_score(prediction,test_y_p))\n",
    "\n",
    "model.fit(train_x_s,train_y_s) \n",
    "prediction=model.predict(test_x_s) \n",
    "print('The accuracy of the Decision Tree using Sepals is:',metrics.accuracy_score(prediction,test_y_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Decision Surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "\n",
    "X = iris.iloc[:, :2]  # Take only the first two features.        \n",
    "y = iris.Species\n",
    "h = .02  # step size in the mesh\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Implement 3 Logistic Regression models with varying values of C\n",
    "clf = LogisticRegression(C=0.01)\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf2 = LogisticRegression(C=1)\n",
    "clf2.fit(X, y)\n",
    "\n",
    "clf3 = LogisticRegression(C=100)\n",
    "clf3.fit(X, y)\n",
    "\n",
    "# Define our usual decision surface bounding plots\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h)\n",
    "                     , np.arange(y_min, y_max, h))\n",
    "y_ = np.arange(y_min, y_max, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "trace1 = go.Heatmap(x=xx[0], y=y_, z=Z,\n",
    "                  colorscale='Viridis',\n",
    "                  showscale=True)\n",
    "\n",
    "trace2 = go.Scatter(x=X[:, 0], y=X[:, 1], \n",
    "                    mode='markers',\n",
    "                    showlegend=False,\n",
    "                    marker=dict(size=10,\n",
    "                                color=y, \n",
    "                                colorscale='Viridis',\n",
    "                                line=dict(color='black', width=1))\n",
    "                    )\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Logistic Regression (C=0.01)',\n",
    "    hovermode= 'closest',\n",
    "    showlegend= False)\n",
    "    \n",
    "data = [trace1, trace2]\n",
    "fig = go.Figure(data=data, layout=layout)       \n",
    "py.iplot(fig)\n",
    "\n",
    "\n",
    "Z = clf2.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "#Z = Z.reshape((xx.shape[0], xx.shape[1], 3))\n",
    "\n",
    "\n",
    "trace3 = go.Heatmap(x=xx[0], y=y_, \n",
    "                    z=Z,\n",
    "                    colorscale='Viridis',\n",
    "                    showscale=True)\n",
    "\n",
    "trace4 = go.Scatter(x=X[:, 0], y=X[:, 1],\n",
    "                    mode='markers',\n",
    "                    showlegend=False,\n",
    "                    marker=dict(size=10,\n",
    "                                color=y, \n",
    "                                colorscale='Viridis',\n",
    "                                line=dict(color='black', width=1))\n",
    "                   )\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Logistic Regression (C=1)',\n",
    "    hovermode= 'closest',\n",
    "    showlegend= False)\n",
    "\n",
    "data = [trace3, trace4]\n",
    "fig2 = go.Figure(data=data,layout= layout)   \n",
    "\n",
    "for i in map(str, range(1, 3)):\n",
    "    x = 'xaxis' + i\n",
    "    y = 'yaxis' + i\n",
    "    fig['layout'][x].update(showgrid=False, zeroline=False,\n",
    "                                   showticklabels=False, ticks='', autorange=True)\n",
    "    fig['layout'][y].update(showgrid=False, zeroline=False,\n",
    "                                   showticklabels=False, ticks='', autorange=True)\n",
    "\n",
    "py.iplot(fig2)\n",
    "\n",
    "del X, y # remove the earlier X and y\n",
    "X = iris.iloc[:, :2]  # Take only the first two features.        \n",
    "y = iris.Species\n",
    "h = .02  # step size in the mesh\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "Z = clf3.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "\n",
    "trace5 = go.Heatmap(x=xx[0], y=y_, \n",
    "                    z=Z,\n",
    "                    colorscale='Viridis',\n",
    "                    showscale=True)\n",
    "\n",
    "trace6 = go.Scatter(x=X[:, 0], y=X[:, 1],\n",
    "                    mode='markers',\n",
    "                    showlegend=False,\n",
    "                    marker=dict(size=10,\n",
    "                                color=y, \n",
    "                                colorscale='Viridis',\n",
    "                                line=dict(color='black', width=1))\n",
    "                   )\n",
    "\n",
    "layout= go.Layout(\n",
    "    autosize= True,\n",
    "    title= 'Logistic Regression (C=100)',\n",
    "    hovermode= 'closest',\n",
    "    showlegend= False)\n",
    "\n",
    "data = [trace5, trace6]\n",
    "fig3 = go.Figure(data=data,layout= layout)   \n",
    "\n",
    "py.iplot(fig3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
